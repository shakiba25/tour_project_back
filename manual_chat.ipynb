{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2fec0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdjango\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# ---------------- UTF-8 Fix Ø¨Ø±Ø§ÛŒ ÙˆÛŒÙ†Ø¯ÙˆØ² ----------------\u001b[39;00m\n\u001b[0;32m      8\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mbuffer, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import io\n",
    "import django\n",
    "import openai\n",
    "\n",
    "# ---------------- UTF-8 Fix Ø¨Ø±Ø§ÛŒ ÙˆÛŒÙ†Ø¯ÙˆØ² ----------------\n",
    "sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding=\"utf-8\")\n",
    "\n",
    "# ---------------- Django Setup ----------------\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "sys.path.append(BASE_DIR)\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"travelproj.settings\")\n",
    "\n",
    "django.setup()\n",
    "\n",
    "# ---------------- OpenAI Config ----------------\n",
    "openai.api_key = \"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\"\n",
    "openai.api_base = \"https://openrouter.ai/api/v1\"\n",
    "MODEL = \"qwen/qwen3-235b-a22b:free\"\n",
    "\n",
    "# ---------------- Imports ----------------\n",
    "from tours.utils.query_searcher import search_tour_chunks\n",
    "from tours.utils.query_filter import get_chunks_for_query\n",
    "\n",
    "\n",
    "# ---------------- Build Prompt ----------------\n",
    "def build_and_answer(user_query, filtered_chunks, retrieved, history):\n",
    "    prompt = \"ğŸ“Œ Ù„ÛŒØ³Øª ØªÙˆØ±Ù‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª. Ø§Ø² Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†:\\n\\n\"\n",
    "\n",
    "    # ---- Ù†ØªØ§ÛŒØ¬ ÙÛŒÙ„ØªØ± ----\n",
    "    prompt += \"âœ… Ù†ØªØ§ÛŒØ¬ ÙÛŒÙ„ØªØ±:\\n\"\n",
    "    for i, c in enumerate(filtered_chunks, 1):\n",
    "        if hasattr(c, \"text\"):   # Ù…Ø¯Ù„ Chunk\n",
    "            prompt += f\"{i}. {c.text}\\n\"\n",
    "        elif isinstance(c, dict) and \"chunk\" in c:  # Ø®Ø±ÙˆØ¬ÛŒ dict\n",
    "            prompt += f\"{i}. {c['chunk'].text}\\n\"\n",
    "        else:\n",
    "            prompt += f\"{i}. {str(c)}\\n\"\n",
    "\n",
    "    # ---- Ù†ØªØ§ÛŒØ¬ similarity search ----\n",
    "    prompt += \"\\nğŸ” Ù†ØªØ§ÛŒØ¬ Ù…Ø´Ø§Ø¨Ù‡Øª:\\n\"\n",
    "    for i, r in enumerate(retrieved, 1):\n",
    "        chunk = r[\"chunk\"] if isinstance(r, dict) else r\n",
    "        prompt += f\"{i}. {chunk.text}\\n\"\n",
    "\n",
    "    # ---- ØªØ§Ø±ÛŒØ®Ú†Ù‡ ----\n",
    "    prompt += \"\\nğŸ•‘ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú¯ÙØªÚ¯Ùˆ:\\n\"\n",
    "    for turn in history:\n",
    "        prompt += f\"- {turn}\\n\"\n",
    "\n",
    "    # ---- Ø³ÙˆØ§Ù„ Ø¬Ø¯ÛŒØ¯ ----\n",
    "    prompt += f\"\\nâ“ Ø³ÙˆØ§Ù„ Ø¬Ø¯ÛŒØ¯ Ú©Ø§Ø±Ø¨Ø±: {user_query}\\n\"\n",
    "    prompt += \"Ù¾Ø§Ø³Ø® Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø§ Ø³Ø§Ø¯Ù‡ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø¯Ù‡.\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# ---------------- Chat Loop ----------------\n",
    "def manual_chat():\n",
    "    history = []\n",
    "\n",
    "    print(\"ğŸ¤– Chatbot Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Øª! Ø¨Ù†ÙˆÛŒØ³ØŒ Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ 'exit' Ø¨Ø²Ù†.\\n\")\n",
    "\n",
    "    while True:\n",
    "        query = input(\"â“ Ù¾Ø±Ø³Ø´: \")\n",
    "        if query.strip().lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"ğŸ‘‹ Ù¾Ø§ÛŒØ§Ù† Ú¯ÙØªÚ¯Ùˆ.\")\n",
    "            break\n",
    "\n",
    "        # --- ÙÛŒÙ„ØªØ± Ùˆ Ú†Ø§Ù†Ú©â€ŒÙ‡Ø§\n",
    "        filtered_tours, filtered_chunks = get_chunks_for_query(query)\n",
    "\n",
    "        # --- similarity search\n",
    "        retrieved = search_tour_chunks(query, top_k=5)\n",
    "\n",
    "        # --- Ø³Ø§Ø®Øª Ù¾Ø±Ø§Ù…Ù¾Øª\n",
    "        answer = build_and_answer(query, filtered_chunks, retrieved, history)\n",
    "\n",
    "        # --- Ù†Ù…Ø§ÛŒØ´\n",
    "        print(\"\\nğŸ’¬ Ù¾Ø§Ø³Ø®:\\n\", answer)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # --- Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡\n",
    "        history.append({\"role\": \"user\", \"content\": query})\n",
    "        history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    manual_chat()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
